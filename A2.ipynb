{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import sklearn\n",
    "\n",
    "\n",
    "original_df = pd.read_csv('top_10000_popular_movies_tmdb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_BAAI = SentenceTransformer('BAAI/bge-small-en')\n",
    "df = pd.read_csv('top_10000_popular_movies_tmdb.csv')\n",
    "\n",
    "# Define a function to generate embeddings for a single feature column\n",
    "df[\"overview_embedding\"] = df[\"overview\"].apply(lambda x: model_BAAI.encode(str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A small animated movie from Marvel and IIRC Blur Studios.']\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the Mario movie about?\"\n",
    "k = 3\n",
    "similarity_dict = {}\n",
    "query_embedding = model_BAAI.encode(query)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    cosine_sim = sklearn.metrics.pairwise.cosine_similarity([row[\"overview_embedding\"]], [query_embedding])[0][0]\n",
    "    similarity_dict[row[\"overview\"]] = cosine_sim\n",
    "\n",
    "top_k_overviews = sorted(similarity_dict.items(), key=lambda item: item[1], reverse=True)[:k]\n",
    "\n",
    "# print(f\"Top {k} overviews with the highest cosine similarities:\")\n",
    "# for overview, similarity in top_k_overviews:\n",
    "#     print(f\"Overview: {overview}\")\n",
    "#     print(f\"Cosine similarity: {similarity}\\n\")\n",
    "\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question \"{query}\". Don't make up any new information:\n",
    "{'\\n'.join([f' - {overview}' for overview, similarity in top_k_overviews])}'''\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_flan = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "inputs = tokenizer(instruction_prompt, return_tensors=\"pt\")\n",
    "outputs = model_flan.generate(**inputs)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
